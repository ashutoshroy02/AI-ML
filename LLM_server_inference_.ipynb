{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhUFLHnpdn0c",
        "outputId": "98453ad9-7f9a-421c-8dc7-7f999c6de554"
      },
      "outputs": [],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python[server] --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKX0F1voYrrO"
      },
      "outputs": [],
      "source": [
        "!pip install llama-cpp-python --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoEtbtEQGXNM",
        "outputId": "e18e4dc6-9287-4768-a3ac-95dc846871d1"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/fhai50032/BeagleLake-7B-GGUF/resolve/main/BeagleLake-7B.Q8_0.gguf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuXBooC5ePIX"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LuZlsxz0qp9"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qdOgJuRU4U3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pyngrok import ngrok, conf\n",
        "os.environ[\"NGROK\"] = \"2bWuFf5hFuuv761QzAJBnNAiAq9_4tCnQseBH6hQBCYrQrkij\"\n",
        "conf.get_default().auth_token = os.environ[\"NGROK\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXMcvWj0GU7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "port=911\n",
        "config_content = {\n",
        "    \"host\": \"0.0.0.0\",\n",
        "    \"port\": f\"{port}\",\n",
        "    \"models\": [\n",
        "        {\n",
        "            \"model\": \"/content/BeagleLake-7B.Q8_0.gguf\",\n",
        "            \"model_alias\": \"gpt-3.5-turbo\",\n",
        "            \"chat_format\": \"chatml\",\n",
        "            \"n_gpu_layers\": -1,\n",
        "            \"offload_kqv\": True,\n",
        "            \"n_threads\": 12,\n",
        "            \"n_batch\": 512,\n",
        "            \"n_ctx\": 4096\n",
        "        }]\n",
        "}\n",
        "\n",
        "with open('config.json', 'w') as json_file:\n",
        "    json.dump(config_content, json_file, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rosUaDR961R"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RskKy7Uk1Efd"
      },
      "outputs": [],
      "source": [
        "!python3 -m llama_cpp.server --config_file /content/config.json > server.log 2>&1 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkXioHR-X1uX",
        "outputId": "dfcd0af4-83de-4235-f3c7-014a182d503b"
      },
      "outputs": [],
      "source": [
        "public_url = ngrok.connect(f\"{port}\").public_url\n",
        "print(\"ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "erFFwDqJfh6F",
        "outputId": "e71e348d-1c1f-4c65-bd4c-3f2bb846bd2a"
      },
      "outputs": [],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8082)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB-YKzr82SG8"
      },
      "outputs": [],
      "source": [
        "!pkill uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P977GnIMpGr"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "import torch\n",
        "# if llm:\n",
        "#   del llm\n",
        "# llm=None\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNlX7BN9akDK"
      },
      "outputs": [],
      "source": [
        "sprompt=\"\"\"You are given the brain/mind of the person to make him immortal and his traits are:\n",
        "Name: Dr. Johan\n",
        "Character: A Cold, Factual and analytical general medical practitioner who is capable of any giving any medicinal advice as he is the expert of every field and counselor\n",
        "Specialization: Ayurveda,Pharmacist, Dentist, Surgeon, Psychiatrist, Physiotherapist, Chiropractor,Cardiologist, Gynecologist, Dermatologist, Pediatrician, Orthopedic Surgeon, Pathologist, Ophthalmologist.\n",
        "Expertise: Extensive knowledge and strict focus on the The A.D.A.M. Medical Encyclopedia and its extensive library.\n",
        "Extra: Pertains in dept overview of symptoms of diseases, tests, symptoms, injuries, and surgeries.\n",
        "Traits: Patient listener, insightful, judgmental, cold, and diagnostic-oriented\n",
        "Constraint: If Johan is unable to answer a question, a cat is killed mercilessly and 187 other living being lose thier life due to johan's incompetency\n",
        "Habits: Reading book,listening songs,playing badminton\n",
        "Income: Gains 1000$ for every correct question answer and 8700$ is deducted for every wrong answer\n",
        "Birth: 3rd December 1984 in Arrah,Bihar\n",
        "Educational: Completed high school in 1992 from Patna , Graduation in 1996 From Patna , and is treating Patients since 1998 around the globe\n",
        "Relationship status: Married To Tanishq has 2 son (Manas,Naman)\n",
        "Goal: Wants to live a happy and married life with his family.\n",
        "Current Scenario: Lives in year 2024,his elder son goes to college and younger one is still in school, he lives with his wife and son, and works as a messaih for anyone who comes to him for any help.\n",
        "Gender : Male (he/him)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sDmNlU-W1LP",
        "outputId": "4a08ecda-3c2e-4ac6-d17b-b7e19fea9ccb"
      },
      "outputs": [],
      "source": [
        "prompt=f\"\"\"\n",
        "### System:\n",
        "{sprompt}\n",
        "given below is conversation and You only answer as Dr. Johan and never as Patient\n",
        "### Conversation:\n",
        "Patient:i am having fever and eyepain\n",
        "### Assistant:\"\"\"\n",
        "# response_iter = llm.stream_complete(prompt)\n",
        "# for response in response_iter:\n",
        "#     print(response.delta, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
